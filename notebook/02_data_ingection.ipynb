{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取り込み - RAWテーブル作成（SQL版）\n",
    "## JSON形式でS3ステージからデータをロードし、追跡可能性のためにファイル名と行番号を保持\n",
    "\n",
    "このnotebookでは、以下の技術要件を満たします：\n",
    "- JSONデータをRAW形式で保存（変換なし）\n",
    "- ソースファイル名と行番号の追跡\n",
    "- 監査目的でのクエリ可能性\n",
    "\n",
    "**実行環境**: Snowflake SQLワークシート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0771643",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE WAREHOUSE YOUR_WAREHOUSE_NAME;\n",
    "USE DATABASE CAPSTONE; \n",
    "USE SCHEMA PUBLIC;\n",
    "USE SYSADMIN;\n",
    "\n",
    "SELECT \n",
    "    CURRENT_WAREHOUSE() as warehouse,\n",
    "    CURRENT_DATABASE() as database,\n",
    "    CURRENT_SCHEMA() as schema;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create KAPA Raw Table (New Firmware Version)\n",
    "CREATE OR REPLACE TABLE KAPA_RAW (\n",
    "    raw_data VARIANT,\n",
    "    source_file_name STRING,\n",
    "    source_file_row_number NUMBER,\n",
    "    load_timestamp TIMESTAMP_LTZ,\n",
    "    etl_batch_id STRING\n",
    ")\n",
    "COMMENT = 'KAPA Firmware Raw ADS-B Data stored in JSON format';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create KBFI Raw Table (Old Firmware Version)\n",
    "CREATE OR REPLACE TABLE KBFI_RAW (\n",
    "    raw_data VARIANT,\n",
    "    source_file_name STRING,\n",
    "    source_file_row_number NUMBER,\n",
    "    load_timestamp TIMESTAMP_LTZ,\n",
    "    etl_batch_id STRING\n",
    ")\n",
    "COMMENT = 'KBFI Firmware Raw ADS-B Data stored in JSON format';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a59bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COPY INTO命令でKAPAデータをロード\n",
    "\n",
    "以下のSQLを実行してKAPAデータをロードします：\n",
    "\n",
    "```sql\n",
    "-- KAPA（新ファームウェア）データのロード\n",
    "-- バッチIDは実行時の日時に基づいて設定してください\n",
    "COPY INTO KAPA_RAW (\n",
    "    raw_data,\n",
    "    source_file_name,\n",
    "    source_file_row_number,\n",
    "    load_timestamp,\n",
    "    etl_batch_id\n",
    ")\n",
    "FROM (\n",
    "    SELECT \n",
    "        $1 as raw_data,                               -- 元のJSONデータ\n",
    "        METADATA$FILENAME as source_file_name,        -- ソースファイル名\n",
    "        METADATA$FILE_ROW_NUMBER as source_file_row_number, -- 行番号\n",
    "        CURRENT_TIMESTAMP() as load_timestamp,        -- ロード時刻\n",
    "        'KAPA_' || TO_VARCHAR(CURRENT_TIMESTAMP(), 'YYYYMMDD_HH24MISS') as etl_batch_id\n",
    "    FROM @YOUR_S3_STAGE/kapa/                        -- 実際のステージ名に変更\n",
    ")\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'JSON'\n",
    "    STRIP_OUTER_ARRAY = FALSE\n",
    "    COMPRESSION = AUTO\n",
    ")\n",
    "ON_ERROR = CONTINUE                                  -- エラーがあっても処理を継続\n",
    "RETURN_FAILED_ONLY = FALSE;                          -- 成功・失敗両方の結果を表示\n",
    "```\n",
    "\n",
    "**注意**: `@YOUR_S3_STAGE`を実際のステージ名に置き換えてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COPY INTO命令でKBFIデータをロード\n",
    "\n",
    "以下のSQLを実行してKBFIデータをロードします：\n",
    "\n",
    "```sql\n",
    "-- KBFI（旧ファームウェア）データのロード\n",
    "COPY INTO KBFI_RAW (\n",
    "    raw_data,\n",
    "    source_file_name,\n",
    "    source_file_row_number,\n",
    "    load_timestamp,\n",
    "    etl_batch_id\n",
    ")\n",
    "FROM (\n",
    "    SELECT \n",
    "        $1 as raw_data,                               -- 元のJSONデータ\n",
    "        METADATA$FILENAME as source_file_name,        -- ソースファイル名\n",
    "        METADATA$FILE_ROW_NUMBER as source_file_row_number, -- 行番号\n",
    "        CURRENT_TIMESTAMP() as load_timestamp,        -- ロード時刻\n",
    "        'KBFI_' || TO_VARCHAR(CURRENT_TIMESTAMP(), 'YYYYMMDD_HH24MISS') as etl_batch_id\n",
    "    FROM @YOUR_S3_STAGE/kbfi/                        -- 実際のステージ名に変更\n",
    ")\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'JSON'\n",
    "    STRIP_OUTER_ARRAY = FALSE\n",
    "    COMPRESSION = AUTO\n",
    ")\n",
    "ON_ERROR = CONTINUE                                  -- エラーがあっても処理を継続\n",
    "RETURN_FAILED_ONLY = FALSE;                          -- 成功・失敗両方の結果を表示\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415562fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## データロード結果の確認\n",
    "\n",
    "### KAPA_RAWテーブルの統計確認\n",
    "\n",
    "```sql\n",
    "-- KAPA_RAWテーブルの基本統計\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(DISTINCT source_file_name) as unique_files,\n",
    "    COUNT(DISTINCT etl_batch_id) as unique_batches,\n",
    "    MIN(load_timestamp) as first_load,\n",
    "    MAX(load_timestamp) as last_load\n",
    "FROM KAPA_RAW;\n",
    "```\n",
    "\n",
    "### KBFI_RAWテーブルの統計確認\n",
    "\n",
    "```sql\n",
    "-- KBFI_RAWテーブルの基本統計\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(DISTINCT source_file_name) as unique_files,\n",
    "    COUNT(DISTINCT etl_batch_id) as unique_batches,\n",
    "    MIN(load_timestamp) as first_load,\n",
    "    MAX(load_timestamp) as last_load\n",
    "FROM KBFI_RAW;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 追跡可能性とファイル監査のためのクエリ例\n",
    "\n",
    "### ファイル別レコード数監査クエリ\n",
    "\n",
    "```sql\n",
    "-- ファイル別のレコード数と行番号範囲を確認\n",
    "SELECT \n",
    "    source_file_name,\n",
    "    COUNT(*) as record_count,\n",
    "    MIN(source_file_row_number) as min_row,\n",
    "    MAX(source_file_row_number) as max_row,\n",
    "    etl_batch_id,\n",
    "    load_timestamp\n",
    "FROM KAPA_RAW \n",
    "GROUP BY source_file_name, etl_batch_id, load_timestamp\n",
    "ORDER BY load_timestamp DESC, source_file_name;\n",
    "```\n",
    "\n",
    "### 特定行追跡クエリ例\n",
    "\n",
    "```sql\n",
    "-- 特定のファイルの特定の行を追跡する例\n",
    "SELECT \n",
    "    source_file_name,\n",
    "    source_file_row_number,\n",
    "    raw_data,\n",
    "    load_timestamp,\n",
    "    etl_batch_id\n",
    "FROM KAPA_RAW \n",
    "WHERE source_file_name = 'example_file.json'\n",
    "  AND source_file_row_number BETWEEN 100 AND 110\n",
    "ORDER BY source_file_row_number;\n",
    "```\n",
    "\n",
    "### データ品質チェッククエリ\n",
    "\n",
    "```sql\n",
    "-- データ品質チェック：ファイル内で行番号が連続しているかチェック\n",
    "WITH row_gaps AS (\n",
    "    SELECT \n",
    "        source_file_name,\n",
    "        source_file_row_number,\n",
    "        LAG(source_file_row_number) OVER (\n",
    "            PARTITION BY source_file_name \n",
    "            ORDER BY source_file_row_number\n",
    "        ) as prev_row_number,\n",
    "        source_file_row_number - LAG(source_file_row_number) OVER (\n",
    "            PARTITION BY source_file_name \n",
    "            ORDER BY source_file_row_number\n",
    "        ) as row_gap\n",
    "    FROM KAPA_RAW\n",
    ")\n",
    "SELECT \n",
    "    source_file_name,\n",
    "    COUNT(*) as gap_count,\n",
    "    MIN(row_gap) as min_gap,\n",
    "    MAX(row_gap) as max_gap\n",
    "FROM row_gaps\n",
    "WHERE row_gap > 1  -- 1より大きいギャップを検出\n",
    "GROUP BY source_file_name\n",
    "ORDER BY gap_count DESC;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SQL版のnotebookを作成しました\n",
    "\n",
    "**重要**: Snowflake SQLワークシート用のnotebook `02_data_ingection_sql.ipynb` を新たに作成いたしました。\n",
    "\n",
    "こちらのnotebookには以下が含まれています：\n",
    "\n",
    "### 完了した作業\n",
    "✅ **追跡可能性を持つRAWテーブルの作成**\n",
    "- KAPA_RAWテーブル（新しいファームウェア）\n",
    "- KBFI_RAW テーブル（古いファームウェア）  \n",
    "- ファイル名と行番号を含む監査可能な設計\n",
    "\n",
    "✅ **COPY INTOコマンドの実装**\n",
    "- JSONデータの元形式での保存\n",
    "- METADATA$FILENAME と METADATA$FILE_ROW_NUMBER を使用した追跡\n",
    "- バッチIDによる処理の追跡\n",
    "\n",
    "✅ **監査とトレーサビリティのクエリ**\n",
    "- ファイル別レコード数の監査\n",
    "- 特定行の追跡クエリ\n",
    "- データ品質チェック\n",
    "\n",
    "### 使用方法\n",
    "1. `02_data_ingection_sql.ipynb` を開く\n",
    "2. 実際のウェアハウス、データベース、スキーマ名を設定\n",
    "3. S3ステージ名を実際の値に更新\n",
    "4. 各セルのSQLを順次実行\n",
    "\n",
    "### 技術要件の達成\n",
    "- ✅ **要件2**: データはJSON形式で変換せずに保存\n",
    "- ✅ **要件3**: ファイル名と行番号の追跡により完全な監査可能性を実現\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10938b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接続のクリーンアップ\n",
    "\n",
    "try:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"Snowflake接続が正常にクローズされました\")\n",
    "except Exception as e:\n",
    "    print(f\"接続クローズエラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## まとめと次のステップ\n",
    "\n",
    "### 完了した作業\n",
    "✅ **追跡可能性を持つRAWテーブルの作成**\n",
    "- KAPA_RAWテーブル（新しいファームウェア）\n",
    "- KBFI_RAW テーブル（古いファームウェア）\n",
    "- ファイル名と行番号を含む監査可能な設計\n",
    "\n",
    "✅ **COPY INTOコマンドの実装**\n",
    "- JSONデータの元形式での保存\n",
    "- METADATA$FILENAME と METADATA$FILE_ROW_NUMBER を使用した追跡\n",
    "- バッチIDによる処理の追跡\n",
    "\n",
    "✅ **監査とトレーサビリティのクエリ**\n",
    "- ファイル別レコード数の監査\n",
    "- 特定行の追跡クエリ\n",
    "- データ品質チェック\n",
    "\n",
    "### 技術要件の達成状況\n",
    "- ✅ **要件2**: データはJSON形式で変換せずに保存\n",
    "- ✅ **要件3**: ファイル名と行番号の追跡により完全な監査可能性を実現\n",
    "\n",
    "### 次のステップ\n",
    "1. S3ステージ名を実際の値に更新\n",
    "2. COPY INTOコマンドの実行\n",
    "3. データロードの確認と検証\n",
    "4. 下流テーブルへの変換パイプラインの構築\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f38c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
